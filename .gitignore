#libraries

import numpy as np
import nltk.corpus import stopword
from nltk.cluster.util import cosine_distance
import networkx as nx

#cleane sentences generator

def read_article(file_name):
    file = open(file_name,"r")
    filedata=file.readlines()
    artcle = filedata[0].split(". ")
    sentences = []
    
    for sentence in article:
        print(sentence)
        sentence.append(sentence.replace("[^a-zA-Z]"," ").split(" "))
        sentence.pop()
    return sentences
